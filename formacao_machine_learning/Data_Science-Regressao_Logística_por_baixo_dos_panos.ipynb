{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color: green; font-size: 30px; font-weight: bold;'>Data Science - Regressão Logística: de baixo dos panos</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='black' style='font-size: 24px;'>1.1 Conhecendo o Dataset</font>\n",
    "<hr style='border: 2px solid black;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando o numpy, pandas e random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Dataset e o Projeto\n",
    "<hr>\n",
    "\n",
    "### Descrição:\n",
    "<p style='font-size: 15px; line-height: 2; margin: 10px 50px; text-align: justify; text-indent: 35px;'>O mercado imobiliário vem sendo objeto de diversos estudos e pesquisas nos últimos tempos. A crise financeira que afeta a economia tem afetado significativamente os investimentos e ganhos advindos deste setor. Este cenário incentiva o aumento do interesse por estudos de previsão de demanda baseados em características deste mercado, dos imóveis e do entorno destes imóveis.</p>\n",
    "\n",
    "<p style='font-size: 15px; line-height: 2; margin: 10px 50px; text-align: justify; text-indent: 35px;'>Neste contexto o objetivo principal do nosso projeto é desenvolver um sistema de avaliação imobiliária utilizando a metodologia de regressões lineares que é uma das técnicas de machine learning.</p>\n",
    "\n",
    "<p style='font-size: 15px; line-height: 2; margin: 10px 50px; text-align: justify; text-indent: 35px;'>Nosso dataset é uma amostra aleatória de tamanho 5000 de imóveis disponíveis para venda no município do Rio de Janeiro.</p>\n",
    "\n",
    "### Dados:\n",
    "<ul style='font-size: 15px; line-height: 2; text-align: justify;'>\n",
    "    <li><b>Valor</b> - Valor (R$) de oferta do imóvel;</li>\n",
    "    <li><b>Area</b> - Área do imóvel em m².</li>\n",
    "    <li><b>Dist_Praia</b> - Distância do imóvel até a praia (km) (em linha reta).</li>\n",
    "    <li><b>Dist_Farmacia</b> - Distância do imóvel até a farmácia mais próxima (km) (em linha reta).</li>\n",
    "    <li><b>Vale_a_pena_comprar</b> - Valor booleano indicando se vale a pena comprar este imóvel.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('Dados/dados_classificacao_multivariavel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valor</th>\n",
       "      <th>Area</th>\n",
       "      <th>Dist_Praia</th>\n",
       "      <th>Dist_Farmacia</th>\n",
       "      <th>vale_a_pena_comprar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4600000</td>\n",
       "      <td>280</td>\n",
       "      <td>0.240925</td>\n",
       "      <td>0.793637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>900000</td>\n",
       "      <td>208</td>\n",
       "      <td>0.904136</td>\n",
       "      <td>0.134494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2550000</td>\n",
       "      <td>170</td>\n",
       "      <td>0.059525</td>\n",
       "      <td>0.423318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550000</td>\n",
       "      <td>100</td>\n",
       "      <td>2.883181</td>\n",
       "      <td>0.525064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2200000</td>\n",
       "      <td>164</td>\n",
       "      <td>0.239758</td>\n",
       "      <td>0.192374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Valor  Area  Dist_Praia  Dist_Farmacia  vale_a_pena_comprar\n",
       "0  4600000   280    0.240925       0.793637                    1\n",
       "1   900000   208    0.904136       0.134494                    1\n",
       "2  2550000   170    0.059525       0.423318                    1\n",
       "3   550000   100    2.883181       0.525064                    0\n",
       "4  2200000   164    0.239758       0.192374                    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor = np.log(dados['Valor'])\n",
    "area = np.log(dados['Area'])\n",
    "dist_Praia = np.log(dados['Dist_Praia'] + 1)\n",
    "dist_Farmacia = np.log(dados['Dist_Farmacia'] + 1)\n",
    "vale_a_pena_comprar = dados['vale_a_pena_comprar']\n",
    "\n",
    "\n",
    "valor = np.array(valor)\n",
    "area = np.array(area)\n",
    "dist_Praia = np.array(dist_Praia)\n",
    "dist_Farmacia = np.array(dist_Farmacia)\n",
    "vale_a_pena_comprar = np.array(vale_a_pena_comprar)\n",
    "\n",
    "\n",
    "X = np.array([valor, area, dist_Praia, dist_Farmacia]).T\n",
    "y = vale_a_pena_comprar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão logística multivariável\n",
    "\n",
    "Agora nosso problema se trata de uma classificação. Quero saber se vale a pena comprar um determinado imóvel. Para isto, vamos usar uma curva logística no lugar de uma linha. A função logística é uma função que varia entre 0 e 1, e é contínuo em todo seu domínio, definida da seguinte forma:\n",
    "\n",
    "$$\n",
    "y = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "\n",
    "Podemos definir isto a partir da notação matricial:\n",
    "\n",
    "$$\n",
    "y = \\frac{1}{1+e^{-X\\bullet \\theta}}\n",
    "$$\n",
    "\n",
    "Onde $\\theta$ são os parâmetros que devem ser otimizados e X são os atributos da amostra em questão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta forma, nosso modelo irá retornar a probabilidade de nossa amostra ser da classe em questão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prever_prob(theta, X):\n",
    "    z = np.dot(X, theta)\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E para classificar nossaas amostras, devemos simplesmente checar se a probabilidade está acima de um limiar desejado (geralmente 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificar(y, limiar):\n",
    "    return y > limiar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos a função de custo. Usaremos a função da entropia cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Entropia Cruzada = \\frac{1}{N}\\sum_{i=1}^N(-y_ilog(y^p_i) - (1 - y_i)log(1 - y^p_i))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia_cruzada(previsto, y):\n",
    "    return (-y * np.log(previsto) - (1 - y) * np.log(1 - previsto)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devemos minimizar nossa função de custo, para isto usamos o gradiente descendente. Nele, usamos a derivada de nossa função de custo, definida como:\n",
    "\n",
    "$$\n",
    "EntropiaCruzada' = \\frac{1}{N}X^T\\bullet(y^p - y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradienteDescendente(theta, X, y, alpha):\n",
    "    previsto = prever_prob(theta, X)\n",
    "    erro = previsto - y\n",
    "    \n",
    "    gradiente = np.dot(X.T, erro) / (len(X))\n",
    "\n",
    "    theta -= alpha*gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método c_ do numpy vai apenas colocar mais um atributo em todas amostras de nosso conjunto. Este ultimo atributo será sempre unitário, e será responsável pela variável independente $\\theta_0$.\n",
    "\n",
    "Após isto, vamos criar nossos pesos de forma aleatória e executar a nossa otimização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.64039360110891\n",
      "0.30685095240804877\n",
      "0.2988254953813712\n",
      "0.29835810745636665\n",
      "0.29806465608454114\n",
      "0.2978085504282278\n",
      "0.2975664466572867\n"
     ]
    }
   ],
   "source": [
    "X_ = X\n",
    "\n",
    "X = np.c_[np.ones(X.shape[0]), X] \n",
    "\n",
    "theta = np.random.rand(X.shape[1])\n",
    "\n",
    "for i in range(7000):\n",
    "    previsto = prever_prob(theta, X)\n",
    "    custo = entropia_cruzada(previsto, y)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(custo)\n",
    "    \n",
    "    gradienteDescendente(theta, X, y, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9962117 , -0.64682391,  2.49355438, -3.63137227,  0.11369866])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificados = classificar(prever_prob(theta, X), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para checar a eficiencia do modelo, vamos usar a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8934"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(classificados == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparando com o Sk-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8904"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lr.predict(X_) == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divisão conjuntos treinamento e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É justo avaliar nosso modelo com os mesmos dados que ele foi treinado?\n",
    "\n",
    "Para melhor avaliar nosso modelo, devemos dividir o conjunto de dados em dois. Um conjunto para o treinamento e outro para o teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divisao_treinamento_teste(X, y, porcentagem_teste, random_seed = 42):\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    X_test, y_test = [], []\n",
    "    \n",
    "    X_train = list(X)\n",
    "    y_train = list(y)\n",
    "    \n",
    "    tam_y = porcentagem_teste * len(y)\n",
    "    \n",
    "    while len(y_test) < tam_y:\n",
    "        index = random.randrange(len(X_train))\n",
    "        X_test.append(X_train.pop(index))\n",
    "        y_test.append(y_train.pop(index))\n",
    "        \n",
    "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = divisao_treinamento_teste(X_, y, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim! Temos um conjunto de dados para o treinamento e outro para o teste. Então vamos treinar nosso modelo usando o conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.028514164989356\n",
      "0.31792324246109216\n",
      "0.3083916430654408\n",
      "0.3057164081458076\n",
      "0.3051437988826891\n",
      "0.30486037452781517\n",
      "0.3045890579056707\n"
     ]
    }
   ],
   "source": [
    "X_train = np.c_[np.ones(X_train.shape[0]), X_train] \n",
    "\n",
    "theta = np.random.rand(X_train.shape[1])\n",
    "\n",
    "for i in range(7000):\n",
    "    previsto = prever_prob(theta, X_train)\n",
    "    custo = entropia_cruzada(previsto, y_train)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(custo)\n",
    "    \n",
    "    gradienteDescendente(theta, X_train, y_train, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.891\n"
     ]
    }
   ],
   "source": [
    "classificados = classificar(prever_prob(theta, X_train), 0.5)\n",
    "print((classificados == y_train).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validar nosso modelo, vamos apenas calcular sua acurácia usando o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "X_test = np.c_[np.ones(X_test.shape[0]), X_test] \n",
    "classificados = classificar(prever_prob(theta, X_test), 0.5)\n",
    "print((classificados == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
